{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pandas numpy matplotlib seaborn rasterio tqdm pyproj shapely scikit-learn tensorflow==2.10.0\n",
    "#! conda install -c conda-forge libgdal -y\n",
    "#! conda install -c conda-forge gdal -y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raster manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "from rasterio import warp, mask, features\n",
    "from rasterio.windows import Window\n",
    "from rasterio.plot import show, reshape_as_image, adjust_band, reshape_as_raster\n",
    "from osgeo import gdal, ogr, osr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulate polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from shapely.geometry import Polygon\n",
    "from pyproj import Proj, Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.controllers.raster import RasterController\n",
    "from src.controllers.pixel import PixelController\n",
    "from src.controllers.tile import TileController\n",
    "from src.layers.dict_class import LandCoverClassDict\n",
    "from src.layers.utilities import cloud_masking, process_data_points, locations_of_pixels, plot_confusion_matrix,read_metadata,search_mtl_params,extract_landsat_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile = gpd.read_file('../data/shape/milagros/milagros.shp')\n",
    "#shapefile = shapefile.to_crs(src.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove folder:  tmpzmgf4r9w Product:  LC08_L1TP_010063_20220817_20220823_02_T1\n",
      "Remove folder:  tmpfrejzsc9 Product:  LC08_L1TP_010063_20210627_20210707_01_T1\n",
      "Remove folder:  tmpxc78i18t Product:  LC08_L1TP_010063_20190606_20190619_01_T1\n",
      "Remove folder:  tmpkk0pjy8j Product:  LC08_L1TP_010063_20200608_20200824_02_T1\n",
      "Remove folder:  tmpfa8kpl9a Product:  LC08_L1TP_010063_20211001_20211013_02_T1\n",
      "Remove folder:  tmp40dz5gwo Product:  LC08_L1TP_010063_20190825_20200826_02_T1\n",
      "Remove folder:  tmpwajm9as_ Product:  LC08_L1TP_010063_20211001_20211013_01_T1\n",
      "Remove folder:  tmpd9o4h6mt Product:  LC08_L1TP_010063_20150713_20200908_02_T1\n",
      "Remove folder:  tmpi4x5l42l Product:  LC08_L1TP_010063_20151204_20170401_01_T1\n",
      "Remove folder:  tmptdjuzqd9 Product:  LC08_L1TP_010063_20150915_20200908_02_T1\n",
      "Remove folder:  tmpl2gtqacc Product:  LC08_L1TP_010063_20220105_20220114_02_T1\n",
      "Remove folder:  tmp1lra_0i3 Product:  LC08_L1TP_010063_20151001_20170403_01_T1\n",
      "Remove folder:  tmpqr1c49iw Product:  LC08_L1TP_010063_20151204_20200908_02_T1\n",
      "Remove folder:  tmpgbczpmxc Product:  LC08_L1TP_010063_20221207_20221213_02_T1\n",
      "Remove folder:  tmpoo4a5a6m Product:  LC08_L1TP_010063_20131011_20200912_02_T1\n",
      "Remove folder:  tmp79_c9nvr Product:  LC08_L1TP_010063_20210627_20210707_02_T1\n",
      "Remove folder:  tmpmeqnqa52 Product:  LC08_L1TP_010063_20190606_20200828_02_T1\n",
      "Remove folder:  tmpj2ekpncu Product:  LC08_L1TP_010063_20141115_20200910_02_T1\n",
      "Remove folder:  tmpw0_dzglc Product:  LC08_L1TP_010063_20151001_20200908_02_T1\n",
      "Remove folder:  tmps_9h95c0 Product:  LC08_L1TP_010063_20131011_20170429_01_T1\n",
      "Remove folder:  tmpn7pf57kq Product:  LC08_L1TP_010063_20200608_20200625_01_T1\n",
      "Remove folder:  tmpcdnpzfsg Product:  LC08_L1TP_010063_20150713_20170407_01_T1\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "mask = '../data/shape/milagros/Milagros.shp'\n",
    "data_tar = os.listdir('../data/images/raw/products/30/')\n",
    "bands_list = []\n",
    "\n",
    "for x in data_tar:\n",
    "    bands, mtl = extract_landsat_images(f'../data/images/raw/products/30/{x}')\n",
    "    metadata = read_metadata(mtl)\n",
    "    product_id = search_mtl_params('LANDSAT_PRODUCT_ID', metadata)\n",
    "    merge = RasterController().merge_rasters(bands, product_id)\n",
    "    crop = RasterController().cut_shape_mask(merge, mask)\n",
    "    toa = RasterController().correct_toa_radiance(crop, metadata)\n",
    "    tmp = mtl.split('/')[3]\n",
    "    shutil.rmtree(f'/tmp/landsat/{tmp}')\n",
    "    print('Remove folder: ', tmp, 'Product: ', product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = '../data/images/processed/products/landsat/toa/2020/LC08_L1TP_010063_20200811_20200918_02_T1_MCT.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4990 4880 (8, 5205, 4990) (8, 5205, 4880)\n",
      "5060 4880 (8, 5205, 5060) (8, 5205, 4880)\n",
      "4900 4880 (8, 5205, 4900) (8, 5205, 4880)\n",
      "5060 4880 (8, 5205, 5060) (8, 5205, 4880)\n"
     ]
    }
   ],
   "source": [
    "raster_cont = RasterController()\n",
    "path = '../data/images/processed/products/landsat/toa/2022/'\n",
    "for x in os.listdir(path):\n",
    "    if x.startswith('LC08_L1TP_010063_20200811_20200918_02_T1_MCT'):  \n",
    "        pass\n",
    "    else:\n",
    "        masked_data, cloud_mask, meta = raster_cont.cut_cloud_mask(f'{path}/{x}')\n",
    "        raster_cont.apply_mask_without_clouds(image, masked_data, cloud_mask, meta, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed\n",
    "RANDOM_SEED = 21\n",
    "\n",
    "# Set random state for Python\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "\n",
    "# Set random state for Python random function\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set random state for NumPy\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set random state for TensorFlow\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info():\n",
    "    tf_version = tf.__version__\n",
    "    gpus = [x.physical_device_desc for x in device_lib.list_local_devices() if x.device_type == 'GPU']\n",
    "    cuda_version = tf.sysconfig.get_build_info()['cuda_version']\n",
    "    cudnn_version = tf.sysconfig.get_build_info()['cudnn_version']\n",
    "    \n",
    "    print('Versión de TensorFlow: {}'.format(tf_version))\n",
    "    print('GPU: {}'.format(gpus))\n",
    "    print('Versión Cuda: {}'.format(cuda_version))\n",
    "    print('Versión Cudnn: {}\\n'.format(cudnn_version))\n",
    "\n",
    "print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary of all classes and class identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_generator(l8_image_datasets, label_dataset, tile_height, tile_width, pixel_locations, batch_size, merge=False):\n",
    "    \"\"\"\n",
    "    Generador de mosaicos para tomar esas localizaciones de píxeles y construir mosaicos del formato adecuado. \n",
    "    Este generador se entrega directamente al modelo `keras` y alimenta continuamente de datos al modelo durante el entrenamiento y la validación.\n",
    "    \"\"\"\n",
    "    # this is a keras compatible data generator which generates data and labels on the fly\n",
    "    # from a set of pixel locations, a list of image datasets, and a label dataset\n",
    "\n",
    "    c = r = 0\n",
    "    i = 0\n",
    "\n",
    "    label_proj = Proj(label_dataset.crs)\n",
    "    l8_proj = Proj(label_dataset.crs)\n",
    "\n",
    "    # assuming all images have the same num of bands\n",
    "    l8_band_count = l8_image_datasets[0].count\n",
    "    band_count = l8_band_count\n",
    "    class_count = len(class_names)\n",
    "    buffer = math.ceil(tile_height / 2)\n",
    "\n",
    "    while True:\n",
    "        # take one off because we don't want the QA band\n",
    "        image_batch = np.zeros(\n",
    "            (batch_size, tile_height, tile_width, band_count-1))\n",
    "        label_batch = np.zeros((batch_size, class_count))\n",
    "        b = 0\n",
    "        while b < batch_size:\n",
    "            # if we're at the end  of the data just restart\n",
    "            if i >= len(pixel_locations):\n",
    "                i = 0\n",
    "            r, c = pixel_locations[i][0]\n",
    "            dataset_index = pixel_locations[i][1]\n",
    "            i += 1\n",
    "            tile = l8_image_datasets[dataset_index].read(list(np.arange(\n",
    "                1, l8_band_count+1)), window=Window(c-buffer, r-buffer, tile_width, tile_height))\n",
    "            if tile.size == 0:\n",
    "                pass\n",
    "            elif np.amax(tile) == 0:  # don't include if it is part of the image with no pixels\n",
    "                pass\n",
    "            elif np.isnan(tile).any() == True or -9999 in tile:\n",
    "                # we don't want tiles containing nan or -999 this comes from edges\n",
    "                # this also takes a while and is inefficient\n",
    "                pass\n",
    "            elif tile.shape != (l8_band_count, tile_width, tile_height):\n",
    "                # print('wrong shape')\n",
    "                # print(tile.shape)\n",
    "                # somehow we're randomly getting tiles without the correct dimensions\n",
    "                pass\n",
    "            elif np.isin(tile[7, :, :], [352, 368, 392, 416, 432, 480, 840, 864, 880, 904, 928, 944, 1352]).any() == True:\n",
    "                # make sure pixel doesn't contain clouds\n",
    "                # this is probably pretty inefficient but only checking width x height for each tile\n",
    "                # read more here: https://prd-wret.s3-us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/atoms/files/LSDS-1873_US_Landsat_ARD_DFCB_0.pdf\n",
    "                # print('Found some cloud.')\n",
    "                # print(tile[7,:,:])\n",
    "                pass\n",
    "            else:\n",
    "                # taking off the QA band\n",
    "                tile = tile[0:7]\n",
    "                # reshape from raster format to image format and standardize according to image wide stats\n",
    "                reshaped_tile = (reshape_as_image(tile) - 982.5) / 1076.5\n",
    "\n",
    "                # get label data\n",
    "                # find gps of that pixel within the image\n",
    "                (x, y) = l8_image_datasets[dataset_index].xy(r, c)\n",
    "\n",
    "                # convert the point we're sampling from to the same projection as the label dataset if necessary\n",
    "                if l8_proj != label_proj:\n",
    "                    transformer = Transformer.from_crs(l8_proj.srs, label_proj.srs, always_xy=True)\n",
    "                    x, y = transformer.transform(x, y)\n",
    "                # reference gps in label_image\n",
    "                row, col = label_dataset.index(x, y)\n",
    "\n",
    "                # find label\n",
    "                # label image could be huge so we need this to just get a single position\n",
    "                window = ((row, row+1), (col, col+1))\n",
    "                data = LandCoverClassDict().merge_classes(label_dataset.read(\n",
    "                    1, window=window, masked=False, boundless=True), \"landsat\")\n",
    "                label = data[0, 0]\n",
    "                # if this label is part of the unclassified area then ignore\n",
    "                if label == 0 or np.isnan(label).any() == True:\n",
    "                    pass\n",
    "                else:\n",
    "                    # add label to the batch in a one hot encoding style\n",
    "                    label_batch[b][label] = 1\n",
    "                    image_batch[b] = reshaped_tile\n",
    "                    b += 1\n",
    "        yield (image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = LandCoverClassDict().get_landsat_dictionary()\n",
    "colors = LandCoverClassDict().get_colors_dictionary()\n",
    "\n",
    "print(\"class landcover:\", class_names, sep=\"\\n\")\n",
    "print(\"colors:\", colors, sep=\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raster exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = '../data/images/processed/labels/landsat/landcover_ecuador_v1.tif'\n",
    "rasters_path = '../data/images/processed/products/landsat/LC08_L1TP_010063_20130808_20200912_02_T1_M.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_controller = RasterController()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labels = raster_controller.open_raster(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_image = raster_controller.read_raster(dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(labels_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_rasters =  [rio.open(f'{rasters_path}/{raster}') for raster in os.listdir(rasters_path)]\n",
    "#print(\"Numero de Rasters de entrenamiento: \", len(dataset_rasters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_dataser = raster_controller.open_raster(rasters_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate balanced training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_controller = PixelController(label_dataset=dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pixels = pixel_controller.generate_training_pixels(image_datasets=[raster_dataser], train_count=500, merge=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Validation\n",
    "- Balanced and accurate dataset.\n",
    "- Actual pixel locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_locations = process_data_points(train_pixels=train_pixels, landsat_datasets=[raster_dataser], dataset_labels=dataset_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Data Locations\n",
    "Now display the class map along with the locations of training pixels on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_of_pixels(labels_image, label_locations, colors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Data Generator\n",
    "Now let's test the data generator to ensure it is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run \"/home/theend/Documentos/Develop/Python/Jupyter/soil_desertification/src/controllers/tile.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tile_controller = TileController(tile_height=128, tile_width=128, pixel_locations=train_pixels, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_batch = None\n",
    "\n",
    "count = 0\n",
    "for (im, label) in tile_generator([raster_dataser], dataset_labels, 128, 128, train_pixels, 10):\n",
    "    if count > 3:\n",
    "        break\n",
    "    print('Image')\n",
    "    print(im.shape)\n",
    "    print('Label')\n",
    "    print(label.shape)\n",
    "    print('----')\n",
    "    count += 1\n",
    "    im_batch = im\n",
    "    label_batch = label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de los mosaicos\n",
    "\n",
    "Ahora vamos a visualizar los azulejos reales. Tenga en cuenta que se verán poco naturales porque han sido normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return (image - np.min(image)) / (np.max(image) - np.min(image) + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_with_labels(image_batch, label_batch, class_names):\n",
    "    num_images = image_batch.shape[0]\n",
    "    num_cols = 3\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(1.62 * 10, 10))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "\n",
    "        axes[row, col].imshow(normalize(image_batch[i, :, :, 3:6]))\n",
    "        axes[row, col].set_title(class_names[np.argmax(label_batch[i])])\n",
    "\n",
    "    # Remove any empty subplots\n",
    "    for i in range(num_images, num_rows * num_cols):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_with_labels(im_batch, label_batch, LandCoverClassDict().get_landsat_dictionary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 1x1 tile training dataset for scikit-learn for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_batch = None\n",
    "label_batch = None\n",
    "\n",
    "sample_size = 500\n",
    "count = 0\n",
    "\n",
    "#tile_controller = TileController(tile_height=1, tile_width=1, pixel_locations=train_pixels, batch_size=500)\n",
    "for (im, label) in tile_generator([raster_dataser], dataset_labels, 1,1, train_pixels, 500):\n",
    "    if count > 0:\n",
    "        break\n",
    "    print('Batch Shape')\n",
    "    print(im.shape)\n",
    "    print('Label Shape')\n",
    "    print(label.shape)\n",
    "    print('----')\n",
    "    count += 1\n",
    "    im_batch = im\n",
    "    label_batch = label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resize\n",
    "Reshape because scikit-learn requires data in the `(samples, features)` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_batch[0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_batch_reshaped = im_batch.reshape(sample_size, 7)\n",
    "im_batch_reshaped[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Spectral Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=[10, 10])\n",
    "\n",
    "# numbers 1-8\n",
    "band_count = np.arange(1, 8)\n",
    "\n",
    "y = np.argmax(label_batch, axis=1)\n",
    "X = im_batch_reshaped\n",
    "\n",
    "classes = np.unique(y)\n",
    "for class_type in classes:\n",
    "    band_intensity = np.mean(X[y == class_type, :], axis=0)\n",
    "    ax.plot(band_count, band_intensity, label=class_names[class_type])\n",
    "# plot them as lines\n",
    "\n",
    "# Add some axis labels\n",
    "ax.set_xlabel('Band #')\n",
    "ax.set_ylabel('Reflectance Value')\n",
    "# Add a titleA\n",
    "ax.set_title('Band Intensities Full Overview')\n",
    "ax.legend(loc='upper left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Actual Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Bidirectional,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    LSTM,\n",
    "    MaxPooling2D,\n",
    "    Reshape,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    ")\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 50  \n",
    "dropout_rate = 0.3\n",
    "\n",
    "# dimensiones de la imagen de entrada\n",
    "tile_side = 32\n",
    "img_rows, img_cols = tile_side, tile_side\n",
    "img_bands = raster_dataser.count - 1\n",
    "num_classes = len(class_names)\n",
    "\n",
    "input_shape = (img_rows, img_cols, img_bands)\n",
    "print(input_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropout_rate = 0.1\n",
    "l1 = tf.keras.regularizers.l1(0)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=input_shape))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', activity_regularizer=l1))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', activity_regularizer=l1, activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same',activity_regularizer=l1, activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', activity_regularizer=l1, activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same', activity_regularizer=l1, activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3200, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "print(\"\\nModel architecture:\\n\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Agregamos una capa de Reshape para convertir la salida en 3D\n",
    "model.add(Reshape((1, 1024)))\n",
    "\n",
    "# Agregamos dos capas Bidirectional LSTM\n",
    "model.add(Bidirectional(LSTM(128, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01))))\n",
    "model.add(Bidirectional(LSTM(64, activation='relu', kernel_regularizer=l2(0.01))))\n",
    "model.add(Dropout(0.5))  # Dropout adicional\n",
    "\n",
    "model.add(Dense(128, kernel_regularizer=l2(0.01)))  # Regularización L2 en capa densa\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))  # Dropout adicional\n",
    "\n",
    "model.add(Dense(128, kernel_regularizer=l2(0.01)))  # Regularización L2 en capa densa\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))  # Dropout adicional\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics and Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(learning_rate=0.0003), metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the Data into Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_val_ratio = 0.7\n",
    "train_px = train_pixels[:int(len(train_pixels)*train_to_val_ratio)]\n",
    "val_px = train_pixels[int(len(train_pixels)*train_to_val_ratio):]\n",
    "print(\"# Training samples: {n_training} \\n# Validation samples: {n_val}\".format(n_training=len(train_px), n_val=len(val_px)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.95):\n",
    "            print(\"\\n Se ha alcanzado el umbral PRESICION. Entrenamiento detenido.....\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "tensorboard = TensorBoard(log_dir='../reports/landsat/v1/logs')\n",
    "checkpoint = ModelCheckpoint('../models/v1/landsat.h5', monitor='accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    tile_generator(\n",
    "        [raster_dataser], \n",
    "        dataset_labels,\n",
    "        tile_side,\n",
    "        tile_side,\n",
    "        train_px,\n",
    "        batch_size,\n",
    "        True\n",
    "    ),\n",
    "    steps_per_epoch=len(train_px) // batch_size, epochs=epochs, verbose=1,\n",
    "    validation_data=tile_generator(\n",
    "        [raster_dataser], \n",
    "        dataset_labels,\n",
    "        tile_side,\n",
    "        tile_side,\n",
    "        val_px,\n",
    "        batch_size,\n",
    "        True\n",
    "    ),\n",
    "    validation_steps=len(val_px) // batch_size,\n",
    "    callbacks=[checkpoint, early_stopping, tensorboard]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Training and Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1.62*7, 7))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "_ = plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1.62*7, 7))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Model error\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "_ = plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Test Accuracy Based on Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    tile_generator(\n",
    "        [raster_dataser], \n",
    "        dataset_labels,\n",
    "        tile_side,\n",
    "        tile_side,\n",
    "        val_px,\n",
    "        batch_size,\n",
    "        True\n",
    "    ),\n",
    "    steps=len(val_px) // batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_generator = tile_generator(\n",
    "        [raster_dataser], \n",
    "        dataset_labels,\n",
    "        tile_side,\n",
    "        tile_side,\n",
    "        val_px,\n",
    "        batch_size,\n",
    "        True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.empty(predictions.shape)\n",
    "count = 0\n",
    "while count < len(labels):\n",
    "    image_b, label_b = next(eval_generator)\n",
    "    labels[count] = label_b\n",
    "    count += 1\n",
    "\n",
    "label_index = np.argmax(labels, axis=1)\n",
    "pred_index = np.argmax(predictions, axis=1)\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Unnormalized Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    label_index,\n",
    "    pred_index,\n",
    "    class_dict=class_names,\n",
    "    title='Confusion matrix - Unnormalized',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Normalized Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_confusion_matrix(\n",
    "    label_index,\n",
    "    pred_index,\n",
    "    class_dict=class_names,\n",
    "    title='Confusion matrix - Normalized',\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {accuracy:.2f}%\".format(accuracy=accuracy_score(label_index, pred_index)*100))\n",
    "print(\"Precision: {precision:.2f}%\".format(precision=precision_score(label_index, pred_index, average='weighted')*100))\n",
    "print(\"Recall: {recall:.2f}%\".format(recall=recall_score(label_index, pred_index, average='weighted')*100))\n",
    "print(\"F1 score: {f1:.2f}%\".format(f1=f1_score(label_index, pred_index, average='weighted')*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Training Accuracy Based on Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    tile_generator(\n",
    "        [raster_dataser], \n",
    "        dataset_labels,\n",
    "        tile_side,\n",
    "        tile_side,\n",
    "        train_px,\n",
    "        batch_size,\n",
    "        True\n",
    "    ),\n",
    "    steps=len(train_px) // batch_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_generator = tile_generator(\n",
    "    [raster_dataser],\n",
    "    dataset_labels,\n",
    "    tile_side,\n",
    "    tile_side,\n",
    "    train_px,\n",
    "    batch_size,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.empty(predictions.shape)\n",
    "count = 0\n",
    "while count < len(labels):\n",
    "    image_b, label_b = next(eval_generator)\n",
    "    labels[count] = label_b\n",
    "    count += 1\n",
    "\n",
    "label_index = np.argmax(labels, axis=1)\n",
    "pred_index = np.argmax(predictions, axis=1)\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Unnormalized Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_confusion_matrix(\n",
    "    label_index,\n",
    "    pred_index,\n",
    "    class_dict=class_names,\n",
    "    title='Confusion matrix - Unnormalized'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Normalized Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_confusion_matrix(\n",
    "    label_index,\n",
    "    pred_index,\n",
    "    class_dict=class_names,\n",
    "    title='Confusion matrix - Normalized',\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {accuracy:.2f}%\".format(accuracy=accuracy_score(label_index, pred_index)*100))\n",
    "print(\"Precision: {precision:.2f}%\".format(precision=precision_score(label_index, pred_index, average='weighted')*100))\n",
    "print(\"Recall: {recall:.2f}%\".format(recall=recall_score(label_index, pred_index, average='weighted')*100))\n",
    "print(\"F1 score: {f1:.2f}%\".format(f1=f1_score(label_index, pred_index, average='weighted')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IPython Notebook execution completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "\n",
    "with rio.open('../data/images/processed/products/landsat/years/2013-2015/LC08_L1TP_010063_20130808_20200912_02_T1_M.tif') as src:\n",
    "    shapefile = gpd.read_file('../data/shape/Ecuador/v_ff010_cobertura_vegetal_2020_a/v_ff010_cobertura_vegetal_2020_aPolygon.shp')\n",
    "    shapefile = shapefile.to_crs(src.crs)\n",
    "    \n",
    "    \n",
    "# Mapear las categorías a valores enteros\n",
    "categories_mapping = {\n",
    "    'SIN INFORMACION': 0,\n",
    "    'BOSQUE': 1,\n",
    "    'CUERPO DE AGUA': 2,\n",
    "    'OTRAS TIERRAS': 3,\n",
    "    'TIERRA AGROPECUARIA': 4,\n",
    "    'VEGETACION ARBUSTIVA Y HERBACEA': 5,\n",
    "    'ZONA ANTROPICA': 6 \n",
    "}\n",
    "\n",
    "shapefile['ctn1'] = shapefile['ctn1'].map(categories_mapping)\n",
    "# Guardar el shapefile con las categorías mapeadas como enteros\n",
    "shapefile.to_file(\"../data/shape/Ecuador/2020/Ecuador-2020.shp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soil-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
